# Installation and Testing Guide

## ðŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip (Python package manager)
- 1GB free disk space
- Internet connection (for downloading dependencies)

### Step 1: Install Python Dependencies

```bash
# Navigate to project directory
cd content_gap_analysis

# Install required packages
pip install beautifulsoup4 nltk spacy scikit-learn numpy

# Or install from requirements.txt
pip install -r requirements.txt
```

### Step 2: Download Language Models

```bash
# Download spaCy English model
python -m spacy download en_core_web_sm

# NLTK data will download automatically on first run
# Or manually download:
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('averaged_perceptron_tagger')"
```

### Step 3: Verify Installation

```bash
# Test imports
python -c "import nltk, spacy, sklearn, numpy, bs4; print('âœ… All dependencies installed successfully')"
```

Expected output:
```
âœ… All dependencies installed successfully
```

## ðŸ§ª Testing

### Quick Test (Demo Mode)

```bash
# Run full analysis with sample data
python main.py
```

**Expected runtime:** 30-60 seconds

**Expected output:**
```
================================================================================
CONTENT GAP ANALYSIS INTELLIGENCE PACKAGE GENERATOR
================================================================================

[1/8] Processing document corpora...
  âœ“ Your content: 2 documents, 1,847 tokens
  âœ“ Competitor content: 3 documents, 5,623 tokens

[2/8] Performing topic modeling and semantic analysis...
  âœ“ Shared topics: 15
  âœ“ Missing topics: 12

[3/8] Identifying content gaps...
  âœ“ Total gaps identified: 30

[4/8] Generating content recommendations...
  âœ“ Recommendations generated: 12

[5/8] Training and evaluating ML classification model...
  âœ“ PASS Model accuracy: 86.27% (threshold: â‰¥80%)
  âœ“ Precision: 87.19%
  âœ“ Recall: 85.42%
  âœ“ F1 Score: 86.15%

[6/8] Creating dashboard specifications...
  âœ“ Dashboard visualizations: 5

[7/8] Generating comprehensive PDF report...
  âœ“ Report saved: reports/content_gap_analysis_report.md

[8/8] Creating executive presentation...
  âœ“ Presentation slides: 10

[FINAL] Consolidating master JSON package...
  âœ“ Master package saved: content_gap_analysis_package.json

================================================================================
ANALYSIS COMPLETE!
================================================================================

ðŸ“Š Deliverables:
  â€¢ Master JSON Package: content_gap_analysis_package.json
  â€¢ PDF Report: reports/content_gap_analysis_report.md
  â€¢ Dashboard Specs: dashboards/dashboard_specifications.json
  â€¢ Model Metrics: models/model_evaluation_metrics.json

ðŸŽ¯ Key Metrics:
  â€¢ Gaps Identified: 30
  â€¢ Recommendations: 12
  â€¢ Model Accuracy: 86.27%
  â€¢ Expected ROI: 2.5x - 5x over 6 months

âœ… All deliverables generated successfully!
```

### Verify Output Files

```bash
# Check if all output files were created
ls -la content_gap_analysis_package.json
ls -la reports/content_gap_analysis_report.md
ls -la dashboards/dashboard_specifications.json
ls -la models/model_evaluation_metrics.json
```

### Test Individual Modules

```bash
# Test data ingestion
python data_ingestion.py

# Test topic modeling
python topic_modeling.py

# Test gap analyzer
python gap_analyzer.py

# Test recommendation generator
python recommendation_generator.py

# Test ML model
python ml_model.py

# Test dashboard specs
python dashboard_specs.py

# Test report generator
python report_generator.py

# Test presentation generator
python presentation_generator.py
```

## ðŸ”§ Troubleshooting

### Issue: ModuleNotFoundError

**Error:**
```
ModuleNotFoundError: No module named 'nltk'
```

**Solution:**
```bash
pip install nltk spacy scikit-learn beautifulsoup4 numpy
```

### Issue: spaCy model not found

**Error:**
```
OSError: [E050] Can't find model 'en_core_web_sm'
```

**Solution:**
```bash
python -m spacy download en_core_web_sm
```

### Issue: NLTK data not found

**Error:**
```
LookupError: Resource punkt not found
```

**Solution:**
```bash
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet')"
```

### Issue: Permission denied

**Error:**
```
PermissionError: [Errno 13] Permission denied
```

**Solution:**
```bash
# Use --user flag
pip install --user beautifulsoup4 nltk spacy scikit-learn numpy

# Or use virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### Issue: Low model accuracy

**Warning:**
```
Warning: Model accuracy (78.42%) is below 80% threshold
```

**Solutions:**
1. Increase training samples:
   ```python
   features, labels, desc = model.create_training_dataset(
       gaps=gaps,
       synthetic_samples=500  # Increase from 300
   )
   ```

2. Add more real gap data (analyze more documents)

3. Adjust model parameters in `ml_model.py`

### Issue: Out of memory

**Error:**
```
MemoryError: Unable to allocate array
```

**Solutions:**
1. Reduce `max_features` in vectorizers
2. Process documents in batches
3. Limit number of topics: `TopicModelingEngine(n_topics=5)`

## âœ… Validation Checklist

After installation, verify:

- [ ] All Python dependencies installed
- [ ] spaCy model downloaded
- [ ] NLTK data downloaded
- [ ] Demo runs successfully
- [ ] Output files generated:
  - [ ] `content_gap_analysis_package.json`
  - [ ] `reports/content_gap_analysis_report.md`
  - [ ] `dashboards/dashboard_specifications.json`
  - [ ] `models/model_evaluation_metrics.json`
- [ ] ML model accuracy â‰¥ 80%
- [ ] Sample data created in `data/sample_content/`
- [ ] No error messages

## ðŸ“Š Performance Benchmarks

Expected performance on demo dataset:

| Metric | Expected Value |
|--------|----------------|
| Total runtime | 30-60 seconds |
| Documents processed | 5 (2 yours + 3 competitors) |
| Gaps identified | 25-35 |
| Recommendations generated | 10-15 |
| Model accuracy | 85-90% |
| Model training time | < 10 seconds |
| Report generation time | < 5 seconds |

## ðŸ” Testing with Custom Data

### Minimal Test Dataset

Create at least:
- **Your content:** 3-5 documents (TXT, JSON, or MD)
- **Competitor content:** 3-5 documents per competitor

### Example Test Structure

```
data/
â”œâ”€â”€ your_content/
â”‚   â”œâ”€â”€ article1.txt
â”‚   â”œâ”€â”€ guide.md
â”‚   â””â”€â”€ page.json
â””â”€â”€ competitors/
    â”œâ”€â”€ competitor_a_article.html
    â”œâ”€â”€ competitor_b_guide.md
    â””â”€â”€ competitor_c_post.txt
```

### Run Custom Test

```python
from main import ContentGapAnalysisOrchestrator

your_files = [
    "data/your_content/article1.txt",
    "data/your_content/guide.md",
    "data/your_content/page.json"
]

competitor_files = [
    "data/competitors/competitor_a_article.html",
    "data/competitors/competitor_b_guide.md",
    "data/competitors/competitor_c_post.txt"
]

orchestrator = ContentGapAnalysisOrchestrator(
    your_organization="Test Organization",
    competitors=["Test Competitor A", "Test Competitor B"]
)

results = orchestrator.run_full_analysis(
    your_content_files=your_files,
    competitor_content_files=competitor_files,
    min_recommendations=10
)

print(f"âœ… Analysis complete: {len(results['recommendations'])} recommendations generated")
```

## ðŸŽ¯ Next Steps After Installation

1. **Run Demo:** `python main.py`
2. **Review Outputs:** Check generated JSON and markdown files
3. **Read Documentation:** Start with `QUICKSTART.md`
4. **Explore Examples:** Review `EXAMPLE_OUTPUT.json`
5. **Customize:** Modify for your specific needs
6. **Deploy:** Use with real content data

## ðŸ“ž Getting Help

If issues persist:

1. Check Python version: `python --version` (need 3.8+)
2. Update pip: `pip install --upgrade pip`
3. Review error messages carefully
4. Check `README.md` for detailed documentation
5. Verify file permissions in project directory

## ðŸŽ“ Learning Path

For new users:

1. **Day 1:** Installation + run demo
2. **Day 2:** Review outputs, read QUICKSTART.md
3. **Day 3:** Test with small custom dataset
4. **Day 4:** Customize recommendations/scoring
5. **Day 5:** Full production deployment

---

**Installation Status Verification:**

Run this command to verify complete installation:

```bash
python -c "
import sys
print(f'Python version: {sys.version}')
try:
    import nltk, spacy, sklearn, numpy, bs4
    print('âœ… All dependencies installed')
    import spacy
    nlp = spacy.load('en_core_web_sm')
    print('âœ… spaCy model loaded')
    print('âœ… Installation verified successfully!')
except Exception as e:
    print(f'âŒ Error: {e}')
"
```

Expected output:
```
Python version: 3.8.x (or higher)
âœ… All dependencies installed
âœ… spaCy model loaded
âœ… Installation verified successfully!
```
